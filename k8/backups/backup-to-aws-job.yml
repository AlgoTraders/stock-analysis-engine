apiVersion: batch/v1
kind: Job
metadata:
  name: sa-dataset-backup-to-aws
  annotations:
    description: The Stock Analysis Dataset Backup to S3 job. This will loop over all the DEFAULT_TICKERS and extract then publish them to the configured S3_ADDRESS endpoint. Set your secrets in the /opt/sa/k8/secrets/secrets.yml file under the ae.k8.aws.s3 section. Once added run: kubectl apply -f /opt/jay/sa/k8/secrets/secrets.yml to add your AWS credentials to this job's runtime.
    runtime: python3
  labels:
    sa: engine
    purpose: stock-analysis
    layer: backend
    messaging: redis
    cache: redis
    pubsub: publisher
spec:
  template:
    metadata:
      labels:
        app: sa-dataset-backup-to-aws
        backend: enabled
        purpose: stock-analysis
        layer: backend
        messaging: redis
        cache: redis
        pubsub: publisher
    spec:
      hostname: sa-dataset-backup-to-aws
      restartPolicy: Never
      containers:
      - image: jayjohnson/stock-analysis-engine:latest
        imagePullPolicy: Always
        name: sa-dataset-backup-to-aws
        resources: {}
        command: ["/bin/bash", "-c", "cd /opt/sa/ && . /opt/venv/bin/activate && /opt/sa/tools/archive-tickers-to-s3.sh -q ${S3_BUCKET}"]
        env:
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: api.db
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: api.db
              key: password
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: api.db
              key: dbname
        - name: S3_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: ae.k8.aws.s3
              key: aws_access_key_id
        - name: S3_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: ae.k8.aws.s3
              key: aws_secret_access_key
        - name: S3_ADDRESS
          valueFrom:
            secretKeyRef:
              name: ae.k8.aws.s3
              key: s3_address
        - name: S3_REGION_NAME
          value: us-west-2
        - name: WORKER_BROKER_URL
          value: redis://redis-master:6379/13
        - name: WORKER_BACKEND_URL
          value: redis://redis-master:6379/14
        - name: REDIS_ADDRESS
          value: redis-master:6379
        - name: REDIS_DB
          value: "0"
        # Stock Analysis - Dataset Backup to S3 Envs:
        - name: S3_BUCKET
          value: ae-stock-datasets
        - name: DEFAULT_TICKERS
          value: SPY,TSLA,AMZN,NFLX
        # set to your Slack webhook url:
        - name: SLACK_WEBHOOK
          value: https://hooks.slack.com/services/YOUR_WEBHOOK_HERE
        # set to "1" to enable publishing to slack when
        # each ticker's job completes
        - name: DATASET_COLLECTION_SLACK_ALERTS
          value: "0"
        # set to "1" to publish Celery task failures to Slack
        - name: PROD_SLACK_ALERTS
          value: "0"
